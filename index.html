<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <!-- These tags force the browser to reload index.html -->
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">

    <title>SEAB Calculator Detector</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom style to ensure video is centered and not flipped */
        #webcam {
            transform: scaleX(1);
        }
    </style>
</head>
<body class="bg-gray-900 text-white min-h-screen flex flex-col items-center justify-center p-4 font-sans">

    <!-- 1. Title Changed -->
    <h1 class="text-3xl font-bold mb-2">SEAB Calculator Detector</h1>
    
    <!-- New line color changed to green -->
    <p class="text-green-500 text-sm mb-4">Delete browsing data for latest update</p>
    
    <!-- 3. Label container moved ABOVE video, with new instruction -->
    <div id="label-container" class="mt-2 mb-4 text-2xl w-full max-w-md text-center text-gray-400">
        Aim camera at Calculator.
    </div>

    <!-- The video element will show the webcam feed -->
    <!-- 'playsinline' and 'muted' are crucial for mobile browsers -->
    <video id="webcam" class="hidden rounded-lg shadow-xl" width="400" height="400" autoplay playsinline muted></video>
    
    <!-- 4. "Switch to OCR" button with blue color -->
    <a href="https://sialaichai.github.io/calculator-scanner/"
       class="mt-8 bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-6 rounded-lg text-lg shadow-lg transition-all">
        Switch to OCR
    </a>

    <!-- Load TensorFlow.js and the Teachable Machine Image model -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
    
    <script type="text/javascript">
        // URL to your Teachable Machine model
        // This is the model you trained!
        const MODEL_URL = "https://teachablemachine.withgoogle.com/models/g2nm_zlLp/";
        
        // Default text for the label
        const defaultLabelText = "Aim camera at Calculator.";

        let model, videoElement, labelContainerElement, maxPredictions;

        videoElement = document.getElementById("webcam");
        labelContainerElement = document.getElementById("label-container");

        // Attempt to auto-start the camera on page load.
        window.addEventListener('load', init);

        // Load the image model and setup the webcam
        async function init() {
            const modelURL = MODEL_URL + "model.json";
            const metadataURL = MODEL_URL + "metadata.json";

            try {
                // Load the model and metadata
                model = await tmImage.load(modelURL, metadataURL);
                maxPredictions = model.getTotalClasses();

                // Setup video element with "exact: environment"
                const constraints = {
                    video: {
                        facingMode: { exact: "environment" },
                        width: 400,
                        height: 400
                    }
                };

                // Use navigator.mediaDevices.getUserMedia directly
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                videoElement.srcObject = stream;
                
                // Wait for the video to be ready
                await new Promise((resolve) => {
                    videoElement.onloadedmetadata = () => {
                        videoElement.play();
                        resolve();
                    };
                });

                // Show the video element
                videoElement.classList.remove("hidden");
                
                // Start the prediction loop
                window.requestAnimationFrame(loop);

            } catch (e) {
                // Handle errors
                console.error(e);
                let errorMsg = "Failed to load model or camera.";
                if (e.name === "OverconstrainedError" || e.name === "NotFoundError") {
                    errorMsg = "Could not find a rear (environment) camera.";
                } else if (e.name === "NotAllowedError") {
                    errorMsg = "Camera permission denied. Please enable it in your browser settings.";
                }
                labelContainerElement.innerHTML = `<div class="text-red-500 text-center">${errorMsg}</div>`;
            }
        }

        // Main prediction loop
        async function loop() {
            await predict();
            window.requestAnimationFrame(loop);
        }

        // Run the webcam image through the image model
        async function predict() {
            // Predict needs the video element
            const prediction = await model.predict(videoElement);

            // Find the prediction with the highest probability
            let topPrediction = prediction[0];
            for (let i = 1; i < maxPredictions; i++) {
                if (prediction[i].probability > topPrediction.probability) {
                    topPrediction = prediction[i];
                }
            }

            // 3. & 4. Display logic updated
            // Only show if accuracy > 80%, with green font
            if (topPrediction.probability > 0.80) {
                const probabilityPercent = (topPrediction.probability * 100).toFixed(0);
                labelContainerElement.innerHTML = `<div class="text-green-500 font-bold">${topPrediction.className}: ${probabilityPercent}%</div>`;
            } else {
                // Otherwise, show the default instruction text
                labelContainerElement.innerHTML = `<div class="text-gray-400">${defaultLabelText}</div>`;
            }
        }
    </script>

</body>
</html>
